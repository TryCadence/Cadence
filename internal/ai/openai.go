package ai

import (
	"context"
	"fmt"
	"strings"

	"github.com/sashabaranov/go-openai"
)

// AnalysisResult contains structured AI analysis output
type AnalysisResult struct {
	Assessment string  // "likely AI-generated", "possibly AI-generated", "unlikely AI-generated"
	Confidence float64 // 0.0-1.0
	Reasoning  string
	Indicators []string
}

// OpenAIAnalyzer uses OpenAI's API for AI-powered analysis
type OpenAIAnalyzer struct {
	client *openai.Client
	config *Config
}

// NewOpenAIAnalyzer creates a new OpenAI analyzer
func NewOpenAIAnalyzer(apiKeyOrConfig interface{}, model ...string) (*OpenAIAnalyzer, error) {
	var apiKey, modelStr string

	// Handle both old (Config) and new (string, string) signatures
	switch v := apiKeyOrConfig.(type) {
	case *Config:
		if v.APIKey == "" {
			return nil, fmt.Errorf("OpenAI API key is required")
		}
		apiKey = v.APIKey
		modelStr = v.Model
	case string:
		apiKey = v
		if len(model) > 0 {
			modelStr = model[0]
		}
		if modelStr == "" {
			modelStr = "gpt-4o-mini"
		}
	default:
		return nil, fmt.Errorf("invalid argument to NewOpenAIAnalyzer")
	}

	client := openai.NewClient(apiKey)
	return &OpenAIAnalyzer{
		client: client,
		config: &Config{
			APIKey:    apiKey,
			Model:     modelStr,
			MaxTokens: 1024,
		},
	}, nil
}

// AnalyzeWithSystemPrompt performs analysis with custom system and user prompts
func (a *OpenAIAnalyzer) AnalyzeWithSystemPrompt(ctx context.Context, systemPrompt, userPrompt string) (string, error) {
	resp, err := a.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: a.config.Model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: systemPrompt,
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: userPrompt,
			},
		},
		MaxTokens:   a.config.MaxTokens,
		Temperature: 0.3,
	})

	if err != nil {
		return "", fmt.Errorf("failed to call OpenAI API: %w", err)
	}

	if len(resp.Choices) == 0 {
		return "", fmt.Errorf("no response from OpenAI")
	}

	return resp.Choices[0].Message.Content, nil
}

// AnalyzeSuspiciousCode sends suspicious code to OpenAI for analysis
func (a *OpenAIAnalyzer) AnalyzeSuspiciousCode(ctx context.Context, commitHash string, additions string) (string, error) {
	result, err := a.analyzeWithReasoning(ctx, commitHash, additions)
	if err != nil {
		return "", err
	}

	// Format for output
	output := fmt.Sprintf("%s (confidence: %.0f%%)", result.Assessment, result.Confidence*100)
	if result.Reasoning != "" {
		output += fmt.Sprintf("\nReasoning: %s", result.Reasoning)
	}
	return output, nil
}

// analyzeWithReasoning performs multi-step AI analysis with structured reasoning
func (a *OpenAIAnalyzer) analyzeWithReasoning(ctx context.Context, commitHash string, additions string) (*AnalysisResult, error) {
	// Limit code size to keep tokens down
	codeSnippet := additions
	if len(codeSnippet) > 2000 {
		codeSnippet = codeSnippet[:2000] + "...[truncated]"
	}

	// Multi-step prompt for better reasoning
	systemPrompt := `You are an expert code analyzer trained to detect AI-generated code patterns and "AI slop". 
Your task is to analyze code and determine the likelihood it was generated by AI.

Consider these AI indicators:

**Code Structure Patterns:**
- Overly generic or template-like code structure
- Perfect code formatting with no "messiness" or inconsistencies
- Functions/classes of suspiciously similar length
- Very consistent indentation and spacing (too perfect)
- Repetitive code patterns or structures

**Naming & Comments:**
- Generic variable names (data, result, value, item, helper, manager)
- Comments that describe obvious code or are overly verbose
- Function names that are overly descriptive yet generic
- Consistent naming conventions that are "too clean"

**Logic & Implementation:**
- Missing error handling or very generic error handling
- Unused imports or variables (common in AI generation)
- Lack of domain-specific optimizations or nuances
- Code that works but isn't optimized for real-world use
- Over-engineered solutions for simple problems

**AI Generation Markers:**
- TODO, FIXME, or placeholder comments
- Boilerplate code patterns
- Code that looks like documentation examples
- Patterns that match common AI training data
- Generic implementation without edge case handling

**Red Flags:**
- Code that's "too perfect" for the complexity of the task
- Excessive explanatory comments for simple logic
- Very balanced code changes (equal additions/deletions)
- Template-like structure with minimal customization

Respond in JSON format:
{
  "assessment": "likely AI-generated|possibly AI-generated|unlikely AI-generated",
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation of key indicators found",
  "indicators": ["specific_pattern1", "specific_pattern2"]
}`

	userPrompt := fmt.Sprintf(`Analyze this code from commit %s:

%s

Provide your assessment in the JSON format specified.`, commitHash[:8], codeSnippet)

	resp, err := a.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: a.config.Model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: systemPrompt,
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: userPrompt,
			},
		},
		MaxTokens:   a.config.MaxTokens,
		Temperature: 0.3,
	})

	if err != nil {
		return nil, fmt.Errorf("failed to call OpenAI API: %w", err)
	}

	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("no response from OpenAI")
	}

	// Parse the response
	return parseAnalysisResult(resp.Choices[0].Message.Content)
}

// parseAnalysisResult extracts structured data from AI response
func parseAnalysisResult(responseText string) (*AnalysisResult, error) {
	result := &AnalysisResult{}

	// Try to extract JSON (improved parsing)
	jsonStart := strings.Index(responseText, "{")
	jsonEnd := strings.LastIndex(responseText, "}")

	if jsonStart == -1 || jsonEnd == -1 {
		// Fallback to simple parsing
		if strings.Contains(responseText, "likely") {
			result.Assessment = "likely AI-generated"
			result.Confidence = 0.8
		} else if strings.Contains(responseText, "possibly") {
			result.Assessment = "possibly AI-generated"
			result.Confidence = 0.5
		} else {
			result.Assessment = "unlikely AI-generated"
			result.Confidence = 0.2
		}
		result.Reasoning = responseText[:min(len(responseText), 200)]
		return result, nil
	}

	jsonStr := responseText[jsonStart : jsonEnd+1]

	// Simple JSON parsing (avoiding extra dependencies)
	if strings.Contains(jsonStr, "likely") {
		result.Assessment = "likely AI-generated"
		result.Confidence = 0.8
	} else if strings.Contains(jsonStr, "possibly") {
		result.Assessment = "possibly AI-generated"
		result.Confidence = 0.5
	} else {
		result.Assessment = "unlikely AI-generated"
		result.Confidence = 0.2
	}

	// Extract confidence if present
	confStart := strings.Index(jsonStr, `"confidence":`)
	if confStart != -1 {
		confStart += 13
		confEnd := strings.IndexAny(jsonStr[confStart:], ",}")
		if confEnd != -1 {
			confStr := strings.TrimSpace(jsonStr[confStart : confStart+confEnd])
			// Try to parse as float (simplified)
			if confStr == "1" || confStr == "1.0" {
				result.Confidence = 1.0
			} else if confStr == "0" || confStr == "0.0" {
				result.Confidence = 0.0
			} else if confStr[0:1] == "0" {
				result.Confidence = 0.5 // Default for uncertain
			}
		}
	}

	// Extract reasoning
	reasonStart := strings.Index(jsonStr, `"reasoning":`)
	if reasonStart != -1 {
		reasonStart += 12
		reasonStart = strings.Index(jsonStr[reasonStart:], `"`) + reasonStart + 1
		reasonEnd := strings.Index(jsonStr[reasonStart:], `"`) + reasonStart
		if reasonEnd > reasonStart {
			result.Reasoning = jsonStr[reasonStart:reasonEnd]
		}
	}

	return result, nil
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// IsConfigured returns whether OpenAI is properly configured
func (a *OpenAIAnalyzer) IsConfigured() bool {
	return a.config.APIKey != ""
}
